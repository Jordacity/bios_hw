---
title: 'Bios 6301: Assignment 5'
output: pdf_document
author: Jordan Clark
---

*Due Tuesday, 10 November, 1:00 PM*

$5^{n=day}$ points taken off for each day late.

50 points total.

Submit a single knitr file (named `homework5.rmd`), along with a valid PDF output file. Inside the file, clearly indicate which parts of your responses go with which problems (you may use the original homework document as a template). Add your name as `author` to the file's metadata section. Raw R code/output or word processor files are not acceptable.

Failure to name file `homework5.rmd` or include author name may result in 5 points taken off.

### Question 1 ###

**20 points**

Import the HAART dataset (`haart.csv`) from the GitHub repository into R, and perform the following manipulations:

1. Convert date columns into a usable (for analysis) format.
```{r}
setwd("~/Desktop/Bios6301")
haart <- read.csv('./datasets/haart.csv')
head(haart)
```
2. Create an indicator variable (one which takes the values 0 or 1 only) to represent death within 1 year of the initial visit.
```{r}
haart[,14] <- as.numeric(haart[,12]-haart[,9])
haart[,15] <- 0 
dim(haart[which(haart[,14]<365),])
haart[,9] <- as.Date(haart[,9],format="%m/%d/%y")
haart[,10] <- as.Date(haart[,10],format="%m/%d/%y") 
haart[,12] <- as.Date(haart[,12],format="%m/%d/%y")
haart[,13] <- format(haart[,9],"%Y")
table(haart[,13])
```

```{r}
for(i in seq(nrow(haart))){
if (is.na(haart[i,14])==F && haart[i,14] < 365) haart[i,15] <- 1 }
sum(haart[,15])

#92 people died. 
```


3. Use the `init.date`, `last visit` and `death.date` to calculate a followup time, which is the difference between the first and either the last visit or a death event (whichever comes first). If these times are longer than 1 year, censor them.

```{r}
for(i in seq(nrow(haart))){
haart[i,16] <- min(as.numeric(haart[i,10] - haart[i,9]), as.numeric(haart[i,12] - haart[i, 9]),na.rm=T)}
haart[,16] <- as.numeric(haart[,16])



for(i in seq(nrow(haart))){
if (is.na(haart[i,16])==FALSE && haart[i,16] > 365) haart[i,16] <- 365 }
quantile(haart[,16],na.rm=T)

head(haart)
```



4. Create another indicator variable representing loss to followup; that is, if their status 1 year after the first visit was unknown.
```{r}
for(i in seq(nrow(haart))){
  haart[i,17] <- 0
if (is.na(haart[i,12])==TRUE && haart[i,10]-haart[i,9] < 365) haart[i,17] <- 1 }
sum(haart[,17])
#173 lost records
```
5. Recall our work in class, which separated the `init.reg` field into a set of indicator variables, one for each unique drug. Create these fields and append them to the database as new columns.
```{r}
reg_list<-strsplit(as.character(haart[,'init.reg']),',') 
str(haart)
head(sapply(reg_list,function(x) 'D4T' %in% x))

all_drugs <- unique(unlist(reg_list))
reg_drugs <- matrix(nrow=nrow(haart),ncol=length(all_drugs)) 

for(i in seq_along(all_drugs)) {
reg_drugs[,i] <- +sapply(reg_list,function(x) all_drugs[i] %in% x) }
reg_drugs <- as.data.frame(reg_drugs)
sapply(reg_drugs, sum)

#3TC, AZT, EFV, NVP, and D4T occur over 100 times.
```
6. The dataset `haart2.csv` contains a few additional observations for the same study. Import these and append them to your master dataset (if you were smart about how you coded the previous steps, cleaning the additional observations should be easy!).

```{r}
haart <- read.csv("./datasets/haart.csv")
haart2 <- read.csv("./datasets/haart2.csv")

haart <- rbind(haart, haart2)
haart[,9] <- as.Date(haart[,9],format="%m/%d/%y")
haart[,10] <- as.Date(haart[,10],format="%m/%d/%y") 
haart[,12] <- as.Date(haart[,12],format="%m/%d/%y")
haart[,13] <- format(haart[,9],"%Y") 

haart[,14] <- as.numeric(haart[,12]-haart[,9]) haart[,15] <- 0

for(i in seq(nrow(haart))){
if (is.na(haart[i,14])==FALSE && haart[i,14] < 365) haart[i,15] <- 1 }

for(i in seq(nrow(haart))){
haart[i,16] <- min(as.numeric(haart[i,10] - haart[i,9]), as.numeric(haart[i,12] - haart[i, }

haart[,16] <- as.numeric(haart[,16])

for(i in seq(nrow(haart))){
if (is.na(haart[i,16])==FALSE && haart[i,16] > 365) haart[i,16] <- 365 }

for(i in seq(nrow(haart))){
  haart[i,17] <- 0
if (is.na(haart[i,12])==TRUE && haart[i,10]-haart[i,9] < 365) haart[i,17] <- 1 }


reg_list<-strsplit(as.character(haart[,'init.reg']),',') 
str(haart)


head(sapply(reg_list,function(x) 'D4T' %in% x))


all_drugs <- unique(unlist(reg_list))
reg_drugs <- matrix(nrow=nrow(haart),ncol=length(all_drugs))

for(i in seq_along(all_drugs)) {
reg_drugs[,i] <- +sapply(reg_list,function(x) all_drugs[i] %in% x) }

colnames(reg_drugs) <- all_drugs 
haart <- cbind(haart, reg_drugs) 
haart[1:5,]

````
### Question 2 ###

**20 points**

Code a function that does golden section search, and use this function to find all of the global maxima on the following function:

$$f(x) = \left\{
  \begin{array}{ll}0 & \text{if } x=0 \\
  |x| \log\left(\frac{|x|}{2}\right)e^{-|x|} & \text{otherwise}
  \end{array}
\right.
$$

on the interval [-10, 10].

To get an idea of what the function looks like, it might be helpful to plot it.

```{r}
haart <- read.csv("haart.csv")

logit <- function(x) 1 / (1 + exp(-x))
haart.complete <- haart[c(4,6:7,11)]
haart.complete <- na.omit(haart.complete)
x <- haart.complete[c(1,2:3)] 
y <- haart.complete[4]

estimate_logit <- function(x, y, MAX_ITER=10) { n <- dim(x)[1]
k <- dim(x)[2]
x <- as.matrix(cbind(rep(1, n), x))
y <- as.matrix(y)

theta <- rep(0, k+1)

J <- rep(0, MAX_ITER)

for (i in 1:MAX_ITER) {

        z <- x %*% theta

h <- logit(z)
        # Calculate gradient
grad <- t((1/n)*x) %*% as.matrix(h - y)
# Calculate Hessian
H <- t((1/n)*x) %*% diag(array(h)) %*% diag(array(1-h)) %*% x
        # Calculate log likelihood
J[i] <- (1/n) %*% sum(-y * log(h) - (1-y) * log(1-h))
#Newton
theta <- theta - solve(H) %*% grad }
return(theta) }
estimate_logit(x, y)

```
### Question 3 ###

**10 points**

Obtain the code for using Newton's Method to estimate logistic regression parameters (`logistic.r`) and modify it to predict `death` from `weight`, `hemoglobin` and `cd4baseline` in the HAART dataset. Use complete cases only. Report the estimates for each parameter, including the intercept.
```{r}
addr <- read.delim("./datasets/addr.txt",sep="\n",header=FALSE,stringsAsFactors=FALSE) 
head(addr)

clean <- c(0,0,0,0,0,0) 
for(i in 1:nrow(addr)){
split <- unlist(strsplit(addr[i,],split=" ")) 
rem <- split[nchar(split)>0]
clean <- rbind(clean,rem)
}

clean <- clean[2:43,]
remstreet <- clean[,3]
street <- data.frame(character(0),character(0))
for(i in 1:nrow(addr)){
split <- unlist(strsplit(remstreet[i],split=" "))
rem <- split[nchar(split)>0]
streetnum <- rem[1]
streetnam <- rem[2:length(rem)]
streetnam <- paste(streetnam,collapse = " ")
street_ <- cbind(streetnum,streetnam)
street <- rbind(street,street_)
}
address <- cbind(clean[,1:2],street,clean[,4:6])

colnames(address) <- c("lastname","firstname", "streetno", "streetname", "city", "state", "zip")
rownames(address) <- NULL
address

```
Note: The original script `logistic_debug.r` is in the exercises folder.  It needs modification, specifically, the logistic function should be defined:

```{r}
logistic <- function(x) 1 / (1 + exp(-x))
```

### Question 4 ###

**5 bonus points**

Import the `addr.txt` file from the GitHub repository.  This file contains a listing of names and addresses (thanks google).  Parse each line to create a data.frame with the following columns: lastname, firstname, streetno, streetname, city, state, zip.  Keep middle initials or abbreviated names in the firstname column.  Print out the entire data.frame.

```{r}
url <- "https://github.com/fonnesbeck/Bios6301/raw/master/datasets/haart.csv" 
haart_df <- read.csv(url)[,c('death','weight','hemoglobin','cd4baseline')] 
coef(summary(glm(death ~ ., data=haart_df, family=binomial(logit))))


funk <- function(dat, response) {
response<- deparse(substitute(response))
form <- as.formula(paste(response, "~.")) 
coef(summary(glm(form, data=dat, family=binomial(logit)))) }
funk(haart_df, death)

```